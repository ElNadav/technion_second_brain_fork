---
aliases:
---

|  | סטודנט א' | סטודנט ב' |
| ---- | ---- | ---- |
| **שם** | עידו פנג בנטוב | ניר קרל |
| **ת"ז** | 322869140 | 322437203 |
| **דואר אלקטרוני** | ido.fang@campus.technion.ac.il | nir.karl@campus.technion.ac.il |


## תרגיל 1

### סעיף א'

הקוד הכולל של סעיף א' וסעיף ב':

```matlab
close all

f = @(x) cos(2*pi*x);
a = -1;
b = 1;
n = [2,5,10,20];

% n derivative of f

f_n = {@(x) -((2*pi)^2)*cos(2*pi*x);
    @(x) -((2*pi)^5)*sin(2*pi*x);
    @(x) -((2*pi)^10)*cos(2*pi*x);
    @(x) ((2*pi)^20)*cos(2*pi*x);};

    
graph_i = figure;
title("Interpolant evaluations");

hold on;
fplot(f,[a,b]);
hold off;
```
```matlab
k = 1;
while k <= length(n)
    % Interpolant evaluation
    
    figure(graph_i);
    
    hold on;
   
    [x,p, phi] = lagrange(f, n(k), a, b);
    plot(x, p);
    
    hold off;
    
    % Absolute error
    graph_e = figure;
    title("n = " + n(k) + " error");
    
    hold on;
    
    fval = feval(f, x);
    e_abs = abs(minus(fval, p));
    plot(x, e_abs, "LineWidth", 2);
    
    % Error boundries
    fnxi = abs(max(feval(f_n{k}, [-1:0.25:1])));
    e_boundry = abs(phi).*(fnxi*(1/factorial(n(k))));
    
    plot(x, e_boundry, "LineWidth", 2);
    
    hold off;
    
    legend("Absolute error", "Error boundry");
    
    k = k + 1;
end

figure(graph_i);
legend("f(x)", "n=2", "n=5", "n=10", "n=20");

```
```matlab
% @param x = the x coordinate to evaluate f for
% @param point_x = x coordinate of points
function w = weight(j, point_x)
    w = 1;
    n = length(point_x);
    for i = 1:n
        if i ~= j
            w = w * (1/(point_x(j)-point_x(i)));
        end
    end
end

function phi = helper_polynom(x, point_x)
    phi = 1;
    n = length(point_x);
    for i = 1:n
        phi = phi * (x - point_x(i));
    end
end


function [x,p,phi] = lagrange(f, n, a, b)
    point_x = a:(b-a)/(n-1):b;
    point_y = feval(f,point_x);
    for j = 1:n
        w(j) = weight(j, point_x);
    end
    
    % evaluate p at 0.01 intervals
    t = 0.01;
    x = a:t:b;
    p = zeros(1, length(x));
    phi = zeros(1, length(x));
    k = 1;
    while k <= length(x)
        for j = 1:n
            p(k) = p(k) + (w(j) * point_y(j))/(x(k) - point_x(j));
        end
        phi(k) = helper_polynom(x(k), point_x);
        p(k) = phi(k) * p(k);
        k = k + 1;
    end
end
```

![[NUM1_HW005/Figure_1.png|book|400]]

>[!notes] הערה: 
 >הגרפים של $f(x)$ ו-$p_{19}$ מאוד דומים, ולכן הם פשוט נמצאים בגרף אחד על השני.
### סעיף ב'

מאחר והנגזרות של $f(x)$ הן כולן פונקציות של $\cos(2\pi x)$ או $\sin(2\pi x)$ בכפולות שונות, ערכן המקסימלי תמיד יתקבל באחד מהערכים:
$$x=-1,-0.75,-0.5,\dots,\, 0.75,\, 1 $$
ולכן מספיק לחשב את ערכי הנגזרת רק בהן. ברור שעבור רוב הנקודות הערכים יהיו זהים, אבל זה רק מוסיף כמה בדיקות בודדות, אז טוב לקחת מקדם ביטחון.

>[!notes] הערה: 
 >ה-$n$ שלנו בשאלה הוא שונה מה-$n$ שנתונה בנוסחה (וזה למה הוגדר $N$ שונה מ-$n$ בשאלה). לכן, בקוד, ה-$n$ שאנו משתמשים בו לחישוב הוא $n-1$, כך שמקבלים את הנוסחה:
 >$$\left|e_{n}(x)\right|\leq \dfrac{1}{(n)!}\cdot\psi(x)\cdot \max_{\xi \in [-1,1]}\left|f^{(n)}(\xi)\right|$$
 
 קיבלנו כי החסם לשגיאה אכן מהווה חסם לשגיאה האמיתית:
 
 
 ![[NUM1_HW005/Figure_2.png|book|400]]
 
![[NUM1_HW005/Figure_3.png|book|400]]

![[NUM1_HW005/Figure_4.png|book|400]]

![[NUM1_HW005/Figure_5.png|book|400]]

## תרגיל 2

### סעיף א'

נחשב את פולינום הבסיס עבור כל אחד מה-$x$ הנתונים:
$$L _{i}=\prod_{\begin{array}{c}
j=0 \\
i\neq j
\end{array}}^{2}=\frac{x-x_{j}}{x_{i}-x_{j}}$$

$$\begin{aligned}
&\begin{aligned}
L_{0}(x):& \\
 & j=0:\; i=j\Longrightarrow \emptyset \\
 & j=1:\; \frac{x-0}{-1-0}=-x \\
 & j=2:\; \frac{x-1}{-1-1}=-\frac{x}{2}+\frac{1}{2} \\
&L_{0}(x)=(-x)\cdot \left(- \frac{x}{2}+\frac{1}{2} \right)=\frac{x^{2}}{2}-\frac{x}{2}
\end{aligned}\\
&\begin{aligned}
L_{1}(x):& \\
&j=0:\; \frac{x-(-1)}{0-(-1)}=x+1 \\
&j=1:\;i=j\Longrightarrow \emptyset \\
&j=2:\; \frac{x-1}{0-1}=-x+1 \\
&L _{1(x)}=(x+1)(-x+1)=-x^{2}+1
\end{aligned}\\
&\begin{aligned}\\
L_{2}(x): \\
& j=0:\;\frac{x-(-1)}{1-(-1)}=\frac{x}{2}+\frac{1}{2} \\
& j=1:\;\frac{x-0}{1-0}=x \\
& j=2:\;i=j\Longrightarrow \emptyset \\
&L _{2}=\left( \frac{x}{2}+\frac{1}{2} \right)\cdot x=\frac{x^{2}}{2}+\frac{x}{2}
\end{aligned}\\
\end{aligned}$$

### סעיף ב'
$$\sum_{i=0}^{2}L _{i}(x)=\left( \frac{x^{2}}{2}-\frac{x}{2} \right)+(-x^{2}+1)+\left( \frac{x^{2}}{2}+\frac{x}{2} \right)=1$$
נשים לב שקיבלנו שהסכום של פולינומי הבסיס קבוע, לכן נשער שלא משנה אילו $x$-ים נבחר, נקבל שהסכום של פולינומי הבסיס הוא 1.

נוכיח את ההשערה:
ניקח פונקציה $f(x)=1$.
לפי הגדרה קירוב פולינומי של פולינום הוא הפולינום עצמו, לכן:
$$P(x)=f(x)=\sum_{i=0}^{n}f(x_{i})L_{i}(x)=\sum_{i=0}^{n}L_{i}(x)$$
מכיוון ש-$P(x)$ הוא קירוב פולינומי של $f(x)$  שבחרנו להיות פולינום מסדר $0$ נקבל ש- $P(x)=1=f(x)$
כלומר:
$$P(x)=1=\sum_{i=0}^{n}L_{i}(x)$$
בהוכחה שהצגנו למעלה, לא הייתה תלות ב-$n$ שמייצג את מספר הנקודות שלנו, כלומר את מספר צמדי האינטרפולציה שיהיו לנו. לכן הסכום של פולינומי הבסיס יהיה 1 לא משנה כמה צמדי אינטרפולציה יהיו לנו.

### סעיף ג'

$$P(x)=\sum_{i=0}^{n}y(x_{j})\prod_{\begin{array}{c}
j=0 \\
j\neq i
\end{array}}^{n}\frac{x-x_{j}}{x_{i}-x_{j}}=\sum_{i=0}^{n}y(x_{j})\cdot \prod_{\begin{array}{c}
j=0 \\
j\neq i
\end{array}}^{n}\frac{1}{x_{i}-x_{j}}\cdot \prod_{\begin{array}{c}
j=0 \\
j\neq i
\end{array}}^{n}x-x_{j}$$
$$\prod_{\begin{array}{c}
j=0 \\
j\neq i
\end{array}}^{n}x-x_{j}=(x-x_{1})(x-x_{2})\dots (x-x_{n-1})(x-x_{n})$$
מכיוון שבכל הגורמים יש לנו $x$ ללא מקדם, תוצאת המכפלה של כל הגורמים תכיל ביטוי של $x^{n}$ ללא מקדם - מכיוון שזוהי תוצאת המכפלה של כל ה-$x$ בכל הגורמים.

לכן נקבל:
$$\sum_{i=0}^{n}y(x_{j})\cdot \prod_{\begin{array}{c}
j=0 \\
j\neq i
\end{array}}^{n}\frac{1}{x_{i}-x_{j}}\cdot \prod_{\begin{array}{c}
j=0 \\
j\neq i
\end{array}}^{n}x-x_{j}=\sum_{i=0}^{n}y(x_{j})\cdot \prod_{\begin{array}{c}
j=0 \\
j\neq i
\end{array}}^{n}\frac{1}{x_{i}-x_{j}}\cdot \Big[x^{n}+p(x)\Big]$$
כאשר $p(x)$ זהו פולינום שמייצג את שאר המכפלות שאינן מכילות את $x^{n}$.
מכאן שהמקדם של $x^{n}$ הוא:
$$\sum_{i=0}^{n}y(x_{j})\cdot \prod_{\begin{array}{c}
j=0 \\
j\neq i
\end{array}}^{n}\frac{1}{x_{i}-x_{j}}$$

## תרגיל 3
$$u(t)={\gamma}_{1}e^{{\gamma}_{2}t}$$
### סעיף א'
לא נוכל להשתמש בשיטת רגרסיה לינארית כדי לפתור ישירות את הבעיה. הסיבה היא שאחד מהתנאים לשימוש בשיטה זו היא שהפונקציה שאליה אנו רוצים להתאים, $u$, תהיה מהצורה הבאה:
$$u(t)=\begin{pmatrix}
{f}_{1}(t) \\
{f}_{2}(t) \\
\vdots 
\end{pmatrix}\begin{pmatrix}
{\gamma}_{1} \\
{\gamma}_{2} \\
\vdots 
\end{pmatrix}=\bar{f}(t)\bar{\gamma}$$
אבל כל הפרמטרים ${\gamma}_{1},{\gamma}_{2}$ לא לינאריים במשוואה שלנו, ולכן לא נוכל לרשום את $u$ בצורה זו.
כן נוכל לפתור את הבעיה הזאת בעקיפין עם שיטת הרגרסיה, אם נגדיר פונקציה חדשה, $v(t)$ כפי שאנו נעשה בסעיף ב'.

### סעיף ב'
$$\begin{aligned}
y(t)&=\ln (u(t)) \\
&=\ln{\gamma}_{1}+{\gamma}_{2} t
\end{aligned}$$
נסמן:
$${\alpha}_{1}=\ln{\gamma}_{1}$$
נבנה את המערכת משוואות:
$$\begin{aligned}
 & {\alpha}_{1}+{\gamma}_{2}{t}_{1}={y}_{1} \\
 & {\alpha}_{1}+{\gamma}_{2}{t}_{2}={y}_{2} \\
 &  \quad \quad \,\,\, \vdots  \\
 & {\alpha}_{1}+{\gamma}_{2}t_{n}=y_{n}
\end{aligned}$$
בצורה מטריצית:
$$\begin{pmatrix}
1 & {t}_{1} \\
1 & {t}_{2} \\
\vdots  & \vdots  \\
1 & t_{n}
\end{pmatrix}\begin{pmatrix}
{\alpha}_{1} \\
{\gamma}_{2}
\end{pmatrix}=\begin{pmatrix}
{y}_{1} \\
{y}_{2} \\
\vdots  \\
y_{n}
\end{pmatrix}$$
נפתור כעת את הבעיה:
	$$\begin{gather}
(A^{T}A)\hat{x}=A^{T}b \\[2ex]
\begin{pmatrix}
1 & 1 & \cdots  & 1 \\
{t}_{1} & {t}_{2} & \cdots  & t_{n}
\end{pmatrix}\begin{pmatrix}
1 & {t}_{1} \\
1 & {t}_{2} \\
\vdots  & \vdots  \\
1 & t_{n}
\end{pmatrix}\begin{pmatrix}
{\alpha}_{1} \\
{\gamma}_{2}
\end{pmatrix}=\begin{pmatrix}
1 & 1 & \cdots  & 1 \\
{t}_{1} & {t}_{2} & \cdots  & t_{n}
\end{pmatrix}\begin{pmatrix}
{y}_{1} \\
{y}_{2} \\
\vdots  \\
y_{n}
\end{pmatrix} \\[2ex]
\begin{pmatrix}
n & \sum_{i=1}^{n}t_{i} \\
\sum_{i=1}^{n}t_{i} & \sum_{n=1}^{n}(t_{i})^{2}  
\end{pmatrix}\begin{pmatrix}
{\alpha}_{1} \\
{\gamma}_{2}
\end{pmatrix}=\begin{pmatrix}
\sum_{i=1}^{n}y_{i} \\
\sum_{i=1}^{n}t_{i}y_{i}  
\end{pmatrix}
\end{gather}$$
את המשוואה הראשונה נוכל לרשום בצורה הבאה:
$$\begin{gather}
n{\alpha}_{1}+{\gamma}_{2}\sum_{i=1}^{n}t_{i}=\sum_{i=1}^{n}y_{i} \\
{\alpha}_{1}=\dfrac{1}{n}\left( \sum_{i=1}^{n} y_{i}-{\gamma}_{2}\sum_{i=1}^{n}t_{i} \right) 
\end{gather}  $$
נציב במשוואה השנייה:
$$\begin{gather}
\sum_{i=1}^{n}t_{i}\cdot \dfrac{1}{n}\left( \sum_{i=1}^{n}y_{i}-{\gamma}_{2}\sum_{i=1}^{n}t_{i}  \right)+ {\gamma}_{2} \sum_{i=1}^{n}(t_{i})^{2}=\sum_{i=1}^{n}t_{i}y_{i} \\[2ex]
\dfrac{1}{n}\cdot \sum_{i=1}^{n}t_{i} \sum_{i=1}^{n}y_{i}-{\gamma}_{2}\cdot \dfrac{1}{n}\cdot\left( \sum_{i=1}^{n}t_{i} \right)^{2}+{\gamma}_{2}\sum_{i=1}^{n}(t_{i})^{2}=\sum_{i=1}^{n}t_{i}y_{i} \\[2ex]
{\gamma}_{2}\left[ \sum_{i=1}^{n}(t_{i})^{2} -\dfrac{1}{n}\left( \sum_{i=1}^{n}t_{i}  \right)^{2}   \right] =\sum_{i=1}^{n}t_{i}y_{i}-\dfrac{1}{n}\sum_{i=1}^{n}t_{i}\sum_{i=1}^{n}y_{i}   \\[2ex]
{\gamma}_{2}=
\end{gather}$$

### סעיף ג'
נציב את הנתונים במערכת משוואות:
$$\begin{gather}
\begin{pmatrix}
n & \sum_{i=1}^{n}t_{i} \\
\sum_{i=1}^{n}t_{i} & \sum_{n=1}^{n}(t_{i})^{2}  
\end{pmatrix}\begin{pmatrix}
{\alpha}_{1} \\
{\gamma}_{2}
\end{pmatrix}=\begin{pmatrix}
\sum_{i=1}^{n}y_{i}\\
\sum_{i=1}^{n}t_{i}y_{i}  
\end{pmatrix} \\[2ex]
\begin{pmatrix}
3 & 3.0 \\
3.0 & 5.0
\end{pmatrix}\begin{pmatrix}
{\alpha}_{1} \\
{\gamma}_{2}
\end{pmatrix}=\begin{pmatrix}
10.9539 \\
17.2378
\end{pmatrix} \\[2ex]
\begin{pmatrix}
3 & 3 \\
0 & 2
\end{pmatrix}\begin{pmatrix}
{\alpha}_{1} \\
{\gamma}_{2}
\end{pmatrix}=\begin{pmatrix}
10.9539 \\
6.2839
\end{pmatrix} \\[2ex]
\begin{pmatrix}
1 & 1 \\
0 & 1
\end{pmatrix}\begin{pmatrix}
{\alpha}_{1} \\
{\gamma}_{2}
\end{pmatrix}=\begin{pmatrix}
3.6513 \\
3.142
\end{pmatrix} \\[2ex]
\begin{pmatrix}
1 & 0 \\
0 & 1
\end{pmatrix}\begin{pmatrix}
{\alpha}_{1} \\
{\gamma}_{2}
\end{pmatrix}=\begin{pmatrix}
0.5093 \\
3.142
\end{pmatrix}
\end{gather}$$
נסיק כי פונקציית הרגרסייה שלנו היא מהצורה:
$$v(t)=0.5093+3.142t$$

